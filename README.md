# TextGenerationWithLSTM

<p>
I've created hopefully easy to understand Text Generation code in jupyter notebook, LSTMs an Word Embedding are used to train the network. If the model reaches good convergance, the generated text will look like the original dataset. Dataset which will be used to be trained uses .txt extension and recommended to have large vocabulary and many words. Feel free to adjust the hyperparameters to reach better convergance. 
</p><br>


## Blog and Paper to read to get more understanding about LSTMs and How the text is generated
<ul>
  <li><a href='http://colah.github.io/posts/2015-08-Understanding-LSTMs'>Understanding LSTM Networks by Christopher Olah</a></li>
  <li><a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness'>Charater-wise RNN by Andrej Karpathy</a></li>
</ul>

## Refrences used in the project 
<ul>
  <li> <a href='https://github.com/vharaymonten/TV-Script-Generation-UdacityProject3'> Udacity Deep Learning Project 3 submission by vharay</a></li>
  <li> <a href='https://github.com/udacity/deep-learning'> Udacity Deep Learning course repository</a></li>
</ul>




    

